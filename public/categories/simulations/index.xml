<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>simulations on The File Drawer</title>
    <link>https://filedrawer.blog/categories/simulations/</link>
    <description>Recent content in simulations on The File Drawer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://filedrawer.blog/categories/simulations/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Do cluster robust standard errors give false positives on cross-level interactions?</title>
      <link>https://filedrawer.blog/post/random-slopes-clustered-errors/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://filedrawer.blog/post/random-slopes-clustered-errors/</guid>
      <description>One of the most easy traps to fall into in quantitative social science is fooling yourself (and your statistics software) into thinking you have more information about a question than you really do.
As always, this is best illustrated with an XKCD comic:
The key point here is that there are only really three independent pieces of information (the three students) and the multiple observations of their yelling are just repeated measurements of the same piece of information rather than new information.</description>
    </item>
    
  </channel>
</rss>
